{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "import seaborn as sns\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import shapefile\r\n",
    "\r\n",
    "# a nice way of filtering out deprecated warnings\r\n",
    "import warnings\r\n",
    "warnings.filterwarnings(\"ignore\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Spark"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "from pyspark.sql import SparkSession\r\n",
    "import warnings\r\n",
    "warnings.filterwarnings(\"ignore\")\r\n",
    "\r\n",
    "# create a spark session (which will run spark jobs)\r\n",
    "spark = SparkSession.builder.getOrCreate()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "21/08/15 13:23:58 WARN Utils: Your hostname, LIVIA resolves to a loopback address: 127.0.1.1; using 172.22.214.215 instead (on interface eth0)\n",
      "21/08/15 13:23:58 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "21/08/15 13:24:00 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Import CSV from January 2019 to March 2019"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "spark.conf.set('spark.sql.execution.arrow.pyspark.enabled', True)\r\n",
    "\r\n",
    "sdf = spark.read.csv('../data/yellow_tripdata_2019-0[1-3].csv', header=True)\r\n",
    "\r\n",
    "f\"{sdf.count():,} rows.\""
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'22,519,712 rows.'"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "spark.conf.set('spark.sql.repl.eagerEval.enabled', True)\r\n",
    "sdf.limit(5)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+\n",
       "|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|RatecodeID|store_and_fwd_flag|PULocationID|DOLocationID|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|\n",
       "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+\n",
       "|       1| 2019-01-01 00:46:40|  2019-01-01 00:53:20|              1|         1.50|         1|                 N|         151|         239|           1|          7|  0.5|    0.5|      1.65|           0|                  0.3|        9.95|                null|\n",
       "|       1| 2019-01-01 00:59:47|  2019-01-01 01:18:59|              1|         2.60|         1|                 N|         239|         246|           1|         14|  0.5|    0.5|         1|           0|                  0.3|        16.3|                null|\n",
       "|       2| 2018-12-21 13:48:30|  2018-12-21 13:52:40|              3|          .00|         1|                 N|         236|         236|           1|        4.5|  0.5|    0.5|         0|           0|                  0.3|         5.8|                null|\n",
       "|       2| 2018-11-28 15:52:25|  2018-11-28 15:55:45|              5|          .00|         1|                 N|         193|         193|           2|        3.5|  0.5|    0.5|         0|           0|                  0.3|        7.55|                null|\n",
       "|       2| 2018-11-28 15:56:57|  2018-11-28 15:58:33|              5|          .00|         2|                 N|         193|         193|           2|         52|    0|    0.5|         0|           0|                  0.3|       55.55|                null|\n",
       "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+"
      ],
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>VendorID</th><th>tpep_pickup_datetime</th><th>tpep_dropoff_datetime</th><th>passenger_count</th><th>trip_distance</th><th>RatecodeID</th><th>store_and_fwd_flag</th><th>PULocationID</th><th>DOLocationID</th><th>payment_type</th><th>fare_amount</th><th>extra</th><th>mta_tax</th><th>tip_amount</th><th>tolls_amount</th><th>improvement_surcharge</th><th>total_amount</th><th>congestion_surcharge</th></tr>\n",
       "<tr><td>1</td><td>2019-01-01 00:46:40</td><td>2019-01-01 00:53:20</td><td>1</td><td>1.50</td><td>1</td><td>N</td><td>151</td><td>239</td><td>1</td><td>7</td><td>0.5</td><td>0.5</td><td>1.65</td><td>0</td><td>0.3</td><td>9.95</td><td>null</td></tr>\n",
       "<tr><td>1</td><td>2019-01-01 00:59:47</td><td>2019-01-01 01:18:59</td><td>1</td><td>2.60</td><td>1</td><td>N</td><td>239</td><td>246</td><td>1</td><td>14</td><td>0.5</td><td>0.5</td><td>1</td><td>0</td><td>0.3</td><td>16.3</td><td>null</td></tr>\n",
       "<tr><td>2</td><td>2018-12-21 13:48:30</td><td>2018-12-21 13:52:40</td><td>3</td><td>.00</td><td>1</td><td>N</td><td>236</td><td>236</td><td>1</td><td>4.5</td><td>0.5</td><td>0.5</td><td>0</td><td>0</td><td>0.3</td><td>5.8</td><td>null</td></tr>\n",
       "<tr><td>2</td><td>2018-11-28 15:52:25</td><td>2018-11-28 15:55:45</td><td>5</td><td>.00</td><td>1</td><td>N</td><td>193</td><td>193</td><td>2</td><td>3.5</td><td>0.5</td><td>0.5</td><td>0</td><td>0</td><td>0.3</td><td>7.55</td><td>null</td></tr>\n",
       "<tr><td>2</td><td>2018-11-28 15:56:57</td><td>2018-11-28 15:58:33</td><td>5</td><td>.00</td><td>2</td><td>N</td><td>193</td><td>193</td><td>2</td><td>52</td><td>0</td><td>0.5</td><td>0</td><td>0</td><td>0.3</td><td>55.55</td><td>null</td></tr>\n",
       "</table>\n"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create a Schema"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "import pyspark.sql.functions as F\r\n",
    "\r\n",
    "from pyspark.sql.types import *\r\n",
    "from pyspark.sql.functions import col"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "ints = ('VendorID', 'passenger_count', 'RatecodeID', \r\n",
    "        'PULocationID', 'DOLocationID', 'payment_type', )\r\n",
    "doubles = ('trip_distance', 'fare_amount', 'extra', \r\n",
    "           'mta_tax', 'tip_amount', 'tolls_amount', \r\n",
    "           'improvement_surcharge', 'total_amount', 'congestion_surcharge')\r\n",
    "strings = ('store_and_fwd_flag',)\r\n",
    "dtimes = ('tpep_pickup_datetime', 'tpep_dropoff_datetime', )\r\n",
    "\r\n",
    "dtypes = {column: IntegerType() for column in ints}\r\n",
    "dtypes.update({column: DoubleType() for column in doubles})\r\n",
    "dtypes.update({column: StringType() for column in strings})\r\n",
    "dtypes.update({column: TimestampType() for column in dtimes})"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "schema = StructType()\r\n",
    "\r\n",
    "for column in sdf.columns:\r\n",
    "    schema.add(column, # column name\r\n",
    "               dtypes[column], # data type\r\n",
    "               True # is nullable?\r\n",
    "              )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "spark.conf.set('spark.sql.execution.arrow.pyspark.enabled', True)\r\n",
    "\r\n",
    "sdf = spark.read.csv('../data/yellow_tripdata_2019-0[1-3].csv', header=True, schema=schema)\r\n",
    "\r\n",
    "f\"{sdf.count():,} rows.\""
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'22,519,712 rows.'"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "sdf.printSchema()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "root\n",
      " |-- VendorID: string (nullable = true)\n",
      " |-- tpep_pickup_datetime: string (nullable = true)\n",
      " |-- tpep_dropoff_datetime: string (nullable = true)\n",
      " |-- passenger_count: string (nullable = true)\n",
      " |-- trip_distance: string (nullable = true)\n",
      " |-- RatecodeID: string (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- PULocationID: string (nullable = true)\n",
      " |-- DOLocationID: string (nullable = true)\n",
      " |-- payment_type: string (nullable = true)\n",
      " |-- fare_amount: string (nullable = true)\n",
      " |-- extra: string (nullable = true)\n",
      " |-- mta_tax: string (nullable = true)\n",
      " |-- tip_amount: string (nullable = true)\n",
      " |-- tolls_amount: string (nullable = true)\n",
      " |-- improvement_surcharge: string (nullable = true)\n",
      " |-- total_amount: string (nullable = true)\n",
      " |-- congestion_surcharge: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "spark.conf.set('spark.sql.repl.eagerEval.enabled', True)\r\n",
    "sdf.limit(5)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+\n",
       "|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|RatecodeID|store_and_fwd_flag|PULocationID|DOLocationID|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|\n",
       "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+\n",
       "|       1| 2019-01-01 00:46:40|  2019-01-01 00:53:20|              1|          1.5|         1|                 N|         151|         239|           1|        7.0|  0.5|    0.5|      1.65|         0.0|                  0.3|        9.95|                null|\n",
       "|       1| 2019-01-01 00:59:47|  2019-01-01 01:18:59|              1|          2.6|         1|                 N|         239|         246|           1|       14.0|  0.5|    0.5|       1.0|         0.0|                  0.3|        16.3|                null|\n",
       "|       2| 2018-12-21 13:48:30|  2018-12-21 13:52:40|              3|          0.0|         1|                 N|         236|         236|           1|        4.5|  0.5|    0.5|       0.0|         0.0|                  0.3|         5.8|                null|\n",
       "|       2| 2018-11-28 15:52:25|  2018-11-28 15:55:45|              5|          0.0|         1|                 N|         193|         193|           2|        3.5|  0.5|    0.5|       0.0|         0.0|                  0.3|        7.55|                null|\n",
       "|       2| 2018-11-28 15:56:57|  2018-11-28 15:58:33|              5|          0.0|         2|                 N|         193|         193|           2|       52.0|  0.0|    0.5|       0.0|         0.0|                  0.3|       55.55|                null|\n",
       "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+"
      ],
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>VendorID</th><th>tpep_pickup_datetime</th><th>tpep_dropoff_datetime</th><th>passenger_count</th><th>trip_distance</th><th>RatecodeID</th><th>store_and_fwd_flag</th><th>PULocationID</th><th>DOLocationID</th><th>payment_type</th><th>fare_amount</th><th>extra</th><th>mta_tax</th><th>tip_amount</th><th>tolls_amount</th><th>improvement_surcharge</th><th>total_amount</th><th>congestion_surcharge</th></tr>\n",
       "<tr><td>1</td><td>2019-01-01 00:46:40</td><td>2019-01-01 00:53:20</td><td>1</td><td>1.5</td><td>1</td><td>N</td><td>151</td><td>239</td><td>1</td><td>7.0</td><td>0.5</td><td>0.5</td><td>1.65</td><td>0.0</td><td>0.3</td><td>9.95</td><td>null</td></tr>\n",
       "<tr><td>1</td><td>2019-01-01 00:59:47</td><td>2019-01-01 01:18:59</td><td>1</td><td>2.6</td><td>1</td><td>N</td><td>239</td><td>246</td><td>1</td><td>14.0</td><td>0.5</td><td>0.5</td><td>1.0</td><td>0.0</td><td>0.3</td><td>16.3</td><td>null</td></tr>\n",
       "<tr><td>2</td><td>2018-12-21 13:48:30</td><td>2018-12-21 13:52:40</td><td>3</td><td>0.0</td><td>1</td><td>N</td><td>236</td><td>236</td><td>1</td><td>4.5</td><td>0.5</td><td>0.5</td><td>0.0</td><td>0.0</td><td>0.3</td><td>5.8</td><td>null</td></tr>\n",
       "<tr><td>2</td><td>2018-11-28 15:52:25</td><td>2018-11-28 15:55:45</td><td>5</td><td>0.0</td><td>1</td><td>N</td><td>193</td><td>193</td><td>2</td><td>3.5</td><td>0.5</td><td>0.5</td><td>0.0</td><td>0.0</td><td>0.3</td><td>7.55</td><td>null</td></tr>\n",
       "<tr><td>2</td><td>2018-11-28 15:56:57</td><td>2018-11-28 15:58:33</td><td>5</td><td>0.0</td><td>2</td><td>N</td><td>193</td><td>193</td><td>2</td><td>52.0</td><td>0.0</td><td>0.5</td><td>0.0</td><td>0.0</td><td>0.3</td><td>55.55</td><td>null</td></tr>\n",
       "</table>\n"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Cleaning the Data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Initial Cleaning"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Find trips that are happening in 2019 and ensure that the pickup time is before the dropoff time"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "sdf = sdf.filter((sdf.tpep_pickup_datetime.startswith('2019')) \r\n",
    "                 & (sdf.tpep_dropoff_datetime.startswith('2019')))\r\n",
    "\r\n",
    "sdf = sdf.filter(sdf.tpep_dropoff_datetime > sdf.tpep_pickup_datetime)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Ensure all trips are not empty within and the maximum passenger count (5)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "sdf = sdf.filter(sdf.passenger_count > 0)\r\n",
    "\r\n",
    "sdf = sdf.filter(sdf.passenger_count < 6)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Ensure all trips are within the minimum fare ($2.5)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "sdf = sdf.filter(sdf.fare_amount > 2.5)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Ensure the trip distance is more than 0.1"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "sdf = sdf.filter((sdf.trip_distance > 0.1))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Find trips paid by credit card (1) and unknown (5)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "payment_id = [1, 5]\r\n",
    "sdf = sdf.filter(F.col(\"payment_type\").isin(payment_id))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Remove trips with unknown location ID (location ID 264 and 265 are unknown location)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "sdf = sdf.filter((sdf.PULocationID < 264))\r\n",
    "sdf = sdf.filter((sdf.DOLocationID < 264))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "# Add duration per second for each record\r\n",
    "diff_hour_col = (col(\"tpep_dropoff_datetime\").cast(\"long\") - col(\"tpep_pickup_datetime\").cast(\"long\"))/3600\r\n",
    "sdf = sdf.withColumn( \"diff_hour\", diff_hour_col )\r\n",
    "\r\n",
    "# Remove trips less than a minute and more than 10 hours\r\n",
    "\r\n",
    "sdf = sdf.filter(sdf.diff_hour <= 10)\r\n",
    "sdf = sdf.filter(sdf.diff_hour > (1/60))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "tip_pct_col = ((col(\"tip_amount\") / col(\"total_amount\"))*100)\r\n",
    "sdf = sdf.withColumn(\"tip_pct\", tip_pct_col)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "sdf.limit(1)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+------------------+------------------+\n",
       "|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|RatecodeID|store_and_fwd_flag|PULocationID|DOLocationID|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|         diff_hour|           tip_pct|\n",
       "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+------------------+------------------+\n",
       "|       1| 2019-01-01 00:46:40|  2019-01-01 00:53:20|              1|          1.5|         1|                 N|         151|         239|           1|        7.0|  0.5|    0.5|      1.65|         0.0|                  0.3|        9.95|                null|0.1111111111111111|16.582914572864322|\n",
       "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+------------------+------------------+"
      ],
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>VendorID</th><th>tpep_pickup_datetime</th><th>tpep_dropoff_datetime</th><th>passenger_count</th><th>trip_distance</th><th>RatecodeID</th><th>store_and_fwd_flag</th><th>PULocationID</th><th>DOLocationID</th><th>payment_type</th><th>fare_amount</th><th>extra</th><th>mta_tax</th><th>tip_amount</th><th>tolls_amount</th><th>improvement_surcharge</th><th>total_amount</th><th>congestion_surcharge</th><th>diff_hour</th><th>tip_pct</th></tr>\n",
       "<tr><td>1</td><td>2019-01-01 00:46:40</td><td>2019-01-01 00:53:20</td><td>1</td><td>1.5</td><td>1</td><td>N</td><td>151</td><td>239</td><td>1</td><td>7.0</td><td>0.5</td><td>0.5</td><td>1.65</td><td>0.0</td><td>0.3</td><td>9.95</td><td>null</td><td>0.1111111111111111</td><td>16.582914572864322</td></tr>\n",
       "</table>\n"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "After initial cleaning, we have:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "f\"{sdf.count():,} rows.\""
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'15,345,130 rows.'"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Adding columns for hour, month, and day_of_week"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "NOTE: for day_of week --> 1 - Sunday, 2 - Monday, 3 - Tuesday, etc"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "sdf = sdf.withColumn('pickup_month', F.month(sdf.tpep_pickup_datetime))\r\n",
    "sdf = sdf.withColumn('pickup_day_of_week', F.dayofweek(sdf.tpep_pickup_datetime))\r\n",
    "sdf = sdf.withColumn('pickup_hour', F.hour(sdf.tpep_pickup_datetime))\r\n",
    "\r\n",
    "sdf = sdf.withColumn('dropoff_month', F.month(sdf.tpep_dropoff_datetime))\r\n",
    "sdf = sdf.withColumn('dropoff_day_of_week', F.dayofweek(sdf.tpep_dropoff_datetime))\r\n",
    "sdf = sdf.withColumn('dropoff_hour', F.hour(sdf.tpep_dropoff_datetime))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "sdf.limit(5)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "21/08/15 13:28:22 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-------------------+------------------+------------+------------------+-----------+-------------+-------------------+------------+\n",
       "|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|RatecodeID|store_and_fwd_flag|PULocationID|DOLocationID|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|          diff_hour|           tip_pct|pickup_month|pickup_day_of_week|pickup_hour|dropoff_month|dropoff_day_of_week|dropoff_hour|\n",
       "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-------------------+------------------+------------+------------------+-----------+-------------+-------------------+------------+\n",
       "|       1| 2019-01-01 00:46:40|  2019-01-01 00:53:20|              1|          1.5|         1|                 N|         151|         239|           1|        7.0|  0.5|    0.5|      1.65|         0.0|                  0.3|        9.95|                null| 0.1111111111111111|16.582914572864322|           1|                 3|          0|            1|                  3|           0|\n",
       "|       1| 2019-01-01 00:59:47|  2019-01-01 01:18:59|              1|          2.6|         1|                 N|         239|         246|           1|       14.0|  0.5|    0.5|       1.0|         0.0|                  0.3|        16.3|                null|               0.32| 6.134969325153374|           1|                 3|          0|            1|                  3|           1|\n",
       "|       1| 2019-01-01 00:21:28|  2019-01-01 00:28:37|              1|          1.3|         1|                 N|         163|         229|           1|        6.5|  0.5|    0.5|      1.25|         0.0|                  0.3|        9.05|                null|0.11916666666666667|13.812154696132595|           1|                 3|          0|            1|                  3|           0|\n",
       "|       1| 2019-01-01 00:32:01|  2019-01-01 00:45:39|              1|          3.7|         1|                 N|         229|           7|           1|       13.5|  0.5|    0.5|       3.7|         0.0|                  0.3|        18.5|                null|0.22722222222222221|              20.0|           1|                 3|          0|            1|                  3|           0|\n",
       "|       1| 2019-01-01 00:57:32|  2019-01-01 01:09:32|              2|          2.1|         1|                 N|         141|         234|           1|       10.0|  0.5|    0.5|       1.7|         0.0|                  0.3|        13.0|                null|                0.2|13.076923076923078|           1|                 3|          0|            1|                  3|           1|\n",
       "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-------------------+------------------+------------+------------------+-----------+-------------+-------------------+------------+"
      ],
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>VendorID</th><th>tpep_pickup_datetime</th><th>tpep_dropoff_datetime</th><th>passenger_count</th><th>trip_distance</th><th>RatecodeID</th><th>store_and_fwd_flag</th><th>PULocationID</th><th>DOLocationID</th><th>payment_type</th><th>fare_amount</th><th>extra</th><th>mta_tax</th><th>tip_amount</th><th>tolls_amount</th><th>improvement_surcharge</th><th>total_amount</th><th>congestion_surcharge</th><th>diff_hour</th><th>tip_pct</th><th>pickup_month</th><th>pickup_day_of_week</th><th>pickup_hour</th><th>dropoff_month</th><th>dropoff_day_of_week</th><th>dropoff_hour</th></tr>\n",
       "<tr><td>1</td><td>2019-01-01 00:46:40</td><td>2019-01-01 00:53:20</td><td>1</td><td>1.5</td><td>1</td><td>N</td><td>151</td><td>239</td><td>1</td><td>7.0</td><td>0.5</td><td>0.5</td><td>1.65</td><td>0.0</td><td>0.3</td><td>9.95</td><td>null</td><td>0.1111111111111111</td><td>16.582914572864322</td><td>1</td><td>3</td><td>0</td><td>1</td><td>3</td><td>0</td></tr>\n",
       "<tr><td>1</td><td>2019-01-01 00:59:47</td><td>2019-01-01 01:18:59</td><td>1</td><td>2.6</td><td>1</td><td>N</td><td>239</td><td>246</td><td>1</td><td>14.0</td><td>0.5</td><td>0.5</td><td>1.0</td><td>0.0</td><td>0.3</td><td>16.3</td><td>null</td><td>0.32</td><td>6.134969325153374</td><td>1</td><td>3</td><td>0</td><td>1</td><td>3</td><td>1</td></tr>\n",
       "<tr><td>1</td><td>2019-01-01 00:21:28</td><td>2019-01-01 00:28:37</td><td>1</td><td>1.3</td><td>1</td><td>N</td><td>163</td><td>229</td><td>1</td><td>6.5</td><td>0.5</td><td>0.5</td><td>1.25</td><td>0.0</td><td>0.3</td><td>9.05</td><td>null</td><td>0.11916666666666667</td><td>13.812154696132595</td><td>1</td><td>3</td><td>0</td><td>1</td><td>3</td><td>0</td></tr>\n",
       "<tr><td>1</td><td>2019-01-01 00:32:01</td><td>2019-01-01 00:45:39</td><td>1</td><td>3.7</td><td>1</td><td>N</td><td>229</td><td>7</td><td>1</td><td>13.5</td><td>0.5</td><td>0.5</td><td>3.7</td><td>0.0</td><td>0.3</td><td>18.5</td><td>null</td><td>0.22722222222222221</td><td>20.0</td><td>1</td><td>3</td><td>0</td><td>1</td><td>3</td><td>0</td></tr>\n",
       "<tr><td>1</td><td>2019-01-01 00:57:32</td><td>2019-01-01 01:09:32</td><td>2</td><td>2.1</td><td>1</td><td>N</td><td>141</td><td>234</td><td>1</td><td>10.0</td><td>0.5</td><td>0.5</td><td>1.7</td><td>0.0</td><td>0.3</td><td>13.0</td><td>null</td><td>0.2</td><td>13.076923076923078</td><td>1</td><td>3</td><td>0</td><td>1</td><td>3</td><td>1</td></tr>\n",
       "</table>\n"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Aggregating the Data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Pickup"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "sdf_pickup = sdf.groupBy(\"PULocationID\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "sdf_pickup_count = sdf_pickup.count().toPandas()\r\n",
    "sdf_pickup_count.to_pickle(\"pickup_count.pkl\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Dropoff"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "sdf_dropoff = sdf.groupBy(\"DOLocationID\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "sdf_dropoff_count = sdf_dropoff.count().toPandas()\r\n",
    "sdf_dropoff_count.to_pickle(\"dropoff_count.pkl\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Pickup Day of Week"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "sdf_pickup_day = sdf.groupBy(\"pickup_day_of_week\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "sdf_pickup_day_count = sdf_pickup_day.count().toPandas()\r\n",
    "sdf_pickup_day_count.to_pickle(\"pickup_day_count.pkl\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Pickup Hour"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "sdf_pickup_hour = sdf.groupBy(\"pickup_hour\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "sdf_pickup_hour_count = sdf_pickup_hour.count().toPandas()\r\n",
    "sdf_pickup_hour_count.to_pickle(\"pickup_hour_count.pkl\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Pickup Month"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "sdf_pickup_month = sdf.groupBy(\"pickup_month\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "sdf_pickup_month_count = sdf_pickup_month.count().toPandas()\r\n",
    "sdf_pickup_month_count.to_pickle(\"pickup_month_count.pkl\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "21/08/15 19:50:10 WARN HeartbeatReceiver: Removing executor driver with no recent heartbeats: 147391 ms exceeds timeout 120000 ms\n",
      "21/08/15 19:50:10 WARN NettyRpcEnv: Ignored failure: java.util.concurrent.TimeoutException: Cannot receive any reply from 172.22.214.215:44193 in 10000 milliseconds\n",
      "21/08/15 19:50:10 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.rpc.RpcTimeoutException: Futures timed out after [10000 milliseconds]. This timeout is controlled by spark.executor.heartbeatInterval\n",
      "\tat org.apache.spark.rpc.RpcTimeout.org$apache$spark$rpc$RpcTimeout$$createRpcTimeoutException(RpcTimeout.scala:47)\n",
      "\tat org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:62)\n",
      "\tat org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:58)\n",
      "\tat scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:38)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:76)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:996)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:212)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1996)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: java.util.concurrent.TimeoutException: Futures timed out after [10000 milliseconds]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:259)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.result(Promise.scala:263)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:293)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\t... 13 more\n",
      "21/08/15 19:50:16 WARN SparkContext: Killing executors is not supported by current scheduler.\n",
      "21/08/15 19:50:16 WARN NettyRpcEnv: Ignored message: HeartbeatResponse(true)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dropping Columns"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "final_sdf = sdf.drop(\"VendorID\",\"store_and_fwd_flag\",\"tpep_pickup_datetime\",\"tpep_dropoff_datetime\",\r\n",
    "                     \"payment_type\", \"extra\", \"mta_tax\", \"tip_amount\", \"total_amount\", \r\n",
    "                     \"improvement_surcharge\", \"congestion_surcharge\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "final_sdf.limit(3)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "+---------------+-------------+----------+------------+------------+-----------+------------+-------------------+------------------+------------+------------------+-----------+-------------+-------------------+------------+\n",
       "|passenger_count|trip_distance|RatecodeID|PULocationID|DOLocationID|fare_amount|tolls_amount|          diff_hour|           tip_pct|pickup_month|pickup_day_of_week|pickup_hour|dropoff_month|dropoff_day_of_week|dropoff_hour|\n",
       "+---------------+-------------+----------+------------+------------+-----------+------------+-------------------+------------------+------------+------------------+-----------+-------------+-------------------+------------+\n",
       "|              1|          1.5|         1|         151|         239|        7.0|         0.0| 0.1111111111111111|16.582914572864322|           1|                 3|          0|            1|                  3|           0|\n",
       "|              1|          2.6|         1|         239|         246|       14.0|         0.0|               0.32| 6.134969325153374|           1|                 3|          0|            1|                  3|           1|\n",
       "|              1|          1.3|         1|         163|         229|        6.5|         0.0|0.11916666666666667|13.812154696132595|           1|                 3|          0|            1|                  3|           0|\n",
       "+---------------+-------------+----------+------------+------------+-----------+------------+-------------------+------------------+------------+------------------+-----------+-------------+-------------------+------------+"
      ],
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>passenger_count</th><th>trip_distance</th><th>RatecodeID</th><th>PULocationID</th><th>DOLocationID</th><th>fare_amount</th><th>tolls_amount</th><th>diff_hour</th><th>tip_pct</th><th>pickup_month</th><th>pickup_day_of_week</th><th>pickup_hour</th><th>dropoff_month</th><th>dropoff_day_of_week</th><th>dropoff_hour</th></tr>\n",
       "<tr><td>1</td><td>1.5</td><td>1</td><td>151</td><td>239</td><td>7.0</td><td>0.0</td><td>0.1111111111111111</td><td>16.582914572864322</td><td>1</td><td>3</td><td>0</td><td>1</td><td>3</td><td>0</td></tr>\n",
       "<tr><td>1</td><td>2.6</td><td>1</td><td>239</td><td>246</td><td>14.0</td><td>0.0</td><td>0.32</td><td>6.134969325153374</td><td>1</td><td>3</td><td>0</td><td>1</td><td>3</td><td>1</td></tr>\n",
       "<tr><td>1</td><td>1.3</td><td>1</td><td>163</td><td>229</td><td>6.5</td><td>0.0</td><td>0.11916666666666667</td><td>13.812154696132595</td><td>1</td><td>3</td><td>0</td><td>1</td><td>3</td><td>0</td></tr>\n",
       "</table>\n"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Export as Pickled Pandas Dataframe"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "final_df_1 = final_sdf.select([\"passenger_count\", \"trip_distance\", \"RatecodeID\", \r\n",
    "                             \"PULocationID\", \"DOLocationID\", \"fare_amount\"]).toPandas()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "final_df_2 = final_sdf.select([\"tolls_amount\", \"diff_hour\", \"tip_pct\", \"pickup_month\", \r\n",
    "                               \"pickup_day_of_week\", \"pickup_hour\", \"dropoff_month\", \r\n",
    "                               \"dropoff_day_of_week\", \"dropoff_hour\"]).toPandas()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "final_df_1.to_pickle(\"../data/final_df_1.pkl\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "final_df_2.to_pickle(\"../data/final_df_2.pkl\")"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}